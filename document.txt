Titanic Survival Prediction Project
Document Overview

Introduction:
The Titanic Survival Prediction project aims to predict passenger survival on the Titanic based on various features. This document provides a comprehensive overview of the analysis, insights gained, and the code implemented during the project.

Data Overview:
The project utilized three datasets:
- Training Data: Loaded from 'train.csv'
- Test Data: Loaded from 'test.csv'
- Gender Submission Data: Loaded from 'gender_submission.csv'

Data Cleaning and Feature Engineering:
1. Numeric Conversion: 'SibSp' and 'Parch' columns were converted to numeric format.
2. Family Size: A new feature 'Family_Size' was created by summing 'SibSp' and 'Parch'.
3. Age Groups: Passengers were categorized into age groups.
4. Deck Information: Extracted from the 'Cabin' column.
5. Ticket Prefixes: Extracted from the 'Ticket' column.
6. Fare Per Person: Calculated as 'Fare' divided by ('Family_Size' + 1).
7. Additional Features: Titles, Is_Alone, Age_Class, Fare_Family, Cabin_Type, Ticket_Length.

Data Visualization:
Visualizations were created to explore relationships between survival and various features, including survival counts by title, family size, age group, deck, ticket prefix, cabin type, and fare per person.

Machine Learning Models:
Three models were trained and evaluated:
1. Logistic Regression
2. Random Forest
3. Support Vector Machine (SVM)

Logistic Regression Model:
- Accuracy: 0.7989
- Precision: 0.79
- Recall: 0.79
- F1-Score: 0.80
- Confusion Matrix: [[87 18] [18 56]]

Random Forest Model:
- Accuracy: 0.8212
- Precision: 0.82
- Recall: 0.81
- F1-Score: 0.82
- Confusion Matrix: [[91 14] [18 56]]

Support Vector Machine (SVM) Model:
- Accuracy: 0.8268
- Precision: 0.82
- Recall: 0.82
- F1-Score: 0.83
- Confusion Matrix: [[92 13] [18 56]]

Hyperparameter Tuning:
The Random Forest model underwent hyperparameter tuning with a grid search. The best parameters were determined to optimize model performance.

Best Hyperparameters:
- 'max_depth': None
- 'min_samples_leaf': 2
- 'min_samples_split': 10
- 'n_estimators': 100

Best Model Evaluation:
- Accuracy: 0.8156
- Precision: 0.81
- Recall: 0.80
- F1-Score: 0.81
- Confusion Matrix: [[92 13] [20 54]]

Results and Insights:
The Random Forest model with tuned hyperparameters yielded the best performance. Feature importance analysis highlighted the significance of certain features, such as 'Sex' and 'Pclass', in predicting survival.

Further Steps:
1. Feature Exploration: Explore additional feature combinations for potential performance improvement.
2. Domain Expert Collaboration: Collaborate with domain experts to gain deeper insights into the dataset.
3. Model Refinement: Continue refining and iterating on the models for better predictive accuracy.

Conclusion:
The project successfully explored, cleaned, and visualized the Titanic dataset. Multiple machine learning models were trained and evaluated, with the Random Forest model providing the best performance. The hyperparameter tuning process further optimized the model. This documentation serves as a comprehensive overview of the project's analysis and insights.


