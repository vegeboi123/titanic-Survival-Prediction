# Titanic Survival Prediction Project - Insights 

## Data Exploration and Cleaning:

- **Numeric Conversion:** 'SibSp' and 'Parch' columns were successfully converted to numeric format for further analysis.
- **Family Size Feature:** The 'Family_Size' feature was created by summing 'SibSp' and 'Parch', providing insights into passengers' family structures.
- **Age Groups:** Passengers were categorized into age groups, revealing the distribution of passengers across different life stages.
- **Deck Information:** Extraction of deck information from the 'Cabin' column allowed understanding of the deck distribution among passengers.
- **Ticket Prefixes:** Extraction of ticket prefixes from the 'Ticket' column helped identify patterns in ticket naming conventions.
- **Fare Per Person:** The 'Fare_Per_Person' feature was calculated, giving an indication of individual fare expenses.
- **Additional Features:** Titles, Is_Alone, Age_Class, Fare_Family, Cabin_Type, and Ticket_Length were introduced to enhance the feature set.

## Data Visualization:

- **Title vs. Survival:** Visualization showed variations in survival counts based on passenger titles, offering insights into social status or gender.
- **Family Size vs. Survival:** Larger families had lower survival rates, emphasizing the challenges faced by larger groups during the disaster.
- **Age Group vs. Survival:** Children had a higher chance of survival, while middle-aged passengers faced increased vulnerability.
- **Deck vs. Survival:** Passengers on certain decks exhibited higher survival rates, possibly indicating proximity to lifeboats.
- **Ticket Prefix vs. Survival:** Survival varied based on ticket prefixes, providing insights into potential groupings or classes.
- **Cabin Type vs. Survival:** Passengers with identified cabin types displayed different survival rates, indicating potential correlations.
- **Fare Per Person Distribution:** Visualization of fare per person highlighted variations in fare expenses across passengers.

## Machine Learning Models:

### Logistic Regression:

- Achieved an accuracy of approximately 79.89%.
- Balanced precision, recall, and F1-Score, suggesting a fair trade-off between different metrics.
- Confusion matrix indicated the model's ability to correctly classify survival outcomes.

### Random Forest:

- Attained an accuracy of about 82.12%.
- Balanced precision, recall, and F1-Score, demonstrating good overall performance.
- Confusion matrix illustrated the distribution of true positives, true negatives, false positives, and false negatives.

### Support Vector Machine (SVM):

- Yielded the highest accuracy of approximately 82.68%.
- Achieved balanced precision, recall, and F1-Score, indicating robust performance.
- Confusion matrix provided insights into the model's ability to correctly predict survival outcomes.

## Best Model - Random Forest:

- Achieved competitive performance with a well-balanced set of metrics.
- Feature importance analysis highlighted the significance of certain features such as 'Sex' and 'Pclass.'
- Hyperparameter tuning further optimized the model, resulting in a well-performing configuration.

## Further Steps:

- Exploration of additional feature combinations may lead to potential performance improvement.
- Collaboration with domain experts could provide deeper insights into the dataset and enhance feature engineering.
- Continued refinement and iteration on the models for better predictive accuracy.

## Conclusion:

The project successfully explored, cleaned, and visualized the Titanic dataset. Multiple machine learning models were trained and evaluated, with the Random Forest model providing the best overall performance. The hyperparameter tuning process further optimized the Random Forest model. This documentation serves as a comprehensive overview of the project's analysis and insights.
